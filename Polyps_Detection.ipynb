{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HDR0fkM16QR",
        "outputId": "d34356a9-0b95-4643-ca61-bd6b8b289a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mamba_ssm\n",
            "  Downloading mamba_ssm-2.2.4.tar.gz (91 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mamba_ssm) (2.6.0+cu124)\n",
            "Collecting ninja (from mamba_ssm)\n",
            "  Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from mamba_ssm) (0.8.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from mamba_ssm) (4.51.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mamba_ssm) (24.2)\n",
            "Requirement already satisfied: setuptools>=61.0.0 in /usr/local/lib/python3.11/dist-packages (from mamba_ssm) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->mamba_ssm)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->mamba_ssm) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mamba_ssm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba_ssm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba_ssm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba_ssm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba_ssm) (2025.1.31)\n",
            "Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Building wheels for collected packages: mamba_ssm\n",
            "  Building wheel for mamba_ssm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba_ssm: filename=mamba_ssm-2.2.4-cp311-cp311-linux_x86_64.whl size=323672993 sha256=8a0be01153fa30727a9e69024fbe061eb92c7ba4416d2049c5fc3107ed91d852\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/5e/64/cfcb5dfe4f854944456e031c34953dc872af1ad7c206145d4a\n",
            "Successfully built mamba_ssm\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mamba_ssm\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed mamba_ssm-2.2.4 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install mamba_ssm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HHm36FTKq4x"
      },
      "source": [
        "## Added bottleneck layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u3mqN2aKqXi",
        "outputId": "3e7b1812-7aee-4e04-f845-4a7b63d6a67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "99bce7417e3e409c9352dc0efab86e5d",
            "ee1e454d20d94cc38ed099398315e7f3",
            "f675afd08b7645e5a9156c39c7acce2d",
            "12e1e806f2fb47dd8de55616ac0fcdad",
            "6f8275931dc9491b9ffd79894d8b54db",
            "c7a497dacf53487bba75f59b7f8aeb5b",
            "749ab214d5ff486a927cedda31a39846",
            "5f0553c5f8594bb6be48e5471adf3d31",
            "6612fae12b0e4591b2d67ed9bac634db",
            "90317f08b5c94bda9423adea0db29fa7",
            "624a4787857c405eb34490a614873963",
            "cfe6973bd09947adb3fd66fe731cc1d7",
            "f0b62aa585d2446cbafd7b9a1146eb05",
            "33317b06342d48bf970e7c1e198933a8",
            "5b918885e96d42abae50853ebee19fd7",
            "61798c596d8d4ab9ad967eaa557b3dc7",
            "26f95247cb9c4a63b5aeae9c0ff4e0ad",
            "156701ddeff3424aa4e7bc0c76201bc8",
            "810432b8707947f09b505f25cffffdda",
            "be1c94bed8cb425d9124b92e19eaddbf",
            "35dfce8ee4b442c2804575046575732f",
            "2b5e9eead7a742088d4180875208585c",
            "fba137eba28b439e805b4969b560d0d3",
            "c875a0ec13d4442ca3231c612d99694f",
            "b25440fd3f4e4a81af2e1e64992b0478",
            "3440f6a96b494219b3168b1aa8c6568b",
            "10f63769b1324b809b5b8386998b35f3",
            "6040c6a40ae04c6893fc70f50a23a7fb",
            "cfdb94c1ba1b4e6fa8108355c3b936cf",
            "d23f65cb3b4b4a6c954cb58bbff46597",
            "50c8c4aa4288459eb9e7934c13244e65",
            "85d0b93f3fb042f68c34a5d32f7bd864",
            "75d314ded7a94790a9a8ce32b746a3dd",
            "37344e75c2254792baf3bd93df24057f",
            "ebe82190935944bfa8e91176f2a9dc3a",
            "50c1a5e0a3b84c7cb920c67600ebb67f",
            "b9d79fa7ebe44c99b687194e7139146b",
            "0974808b8f5644e2a97e87029168bea3",
            "a7fe137f1abb4f00a97c637b9469227e",
            "53078cb4c3db411a8c76d351d550b44b",
            "6ef8ebbb92f6483b8fa8f070ba3fc44c",
            "0a486c47a098445a95e4b840f3a292ea",
            "868c8fdb7d874b699c892fe317460958",
            "1111fa5d733a4138baa23a6df22c55c2"
          ]
        },
        "id": "zLRCWuPvUw1Z",
        "outputId": "de879da3-7254-4741-a5d7-7a92e541893e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/36.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99bce7417e3e409c9352dc0efab86e5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_mambavision.py:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfe6973bd09947adb3fd66fe731cc1d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nvidia/MambaVision-S-1K:\n",
            "- configuration_mambavision.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_mambavision.py:   0%|          | 0.00/27.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fba137eba28b439e805b4969b560d0d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nvidia/MambaVision-S-1K:\n",
            "- modeling_mambavision.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/201M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37344e75c2254792baf3bd93df24057f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MambaVisionModelForImageClassification(\n",
              "  (model): MambaVision(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Identity()\n",
              "      (conv_down): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (levels): ModuleList(\n",
              "      (0): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.012)\n",
              "          )\n",
              "          (2): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.024)\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.035)\n",
              "          )\n",
              "          (1): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.047)\n",
              "          )\n",
              "          (2): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.059)\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.071)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.082)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.094)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.106)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.118)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.129)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.141)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.153)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.165)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.176)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.188)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.200)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\"nvidia/MambaVision-S-1K\", trust_remote_code=True)\n",
        "model.cuda()  # Move model to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YyNaM1vN9h7h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.Conv2d(dim, dim*4, kernel_size=1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(dim*4, dim, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        original_shape = x.shape\n",
        "        input_dim = x.dim()\n",
        "\n",
        "        # Handle 3D input [B, L, C]\n",
        "        if input_dim == 3:\n",
        "            B, L, C = x.shape\n",
        "            H = W = int(L**0.5)  # Assume square patches\n",
        "            x = x.view(B, H, W, C).permute(0, 3, 1, 2)\n",
        "\n",
        "        # Handle 4D input [B, H, W, C]\n",
        "        elif input_dim == 4 and x.shape[-1] == self.dim:\n",
        "            x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Handle unexpected shapes\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected input shape: {original_shape}\")\n",
        "\n",
        "        # Apply convolution\n",
        "        x = self.conv(x)\n",
        "\n",
        "        # Restore original shape\n",
        "        if input_dim == 3:\n",
        "            x = x.permute(0, 2, 3, 1).reshape(B, L, C)\n",
        "        else:  # input_dim == 4\n",
        "            x = x.permute(0, 2, 3, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Insert into levels[2]\n",
        "level_2 = model.model.levels[2]\n",
        "level_2.blocks.insert(3, Bottleneck(dim=384))  # Adjust index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnuA49Zq2XUk",
        "outputId": "633d269f-e017-448f-80c1-a674d407e115"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MambaVisionModelForImageClassification(\n",
              "  (model): MambaVision(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Identity()\n",
              "      (conv_down): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (levels): ModuleList(\n",
              "      (0): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.012)\n",
              "          )\n",
              "          (2): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.024)\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.035)\n",
              "          )\n",
              "          (1): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.047)\n",
              "          )\n",
              "          (2): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.059)\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.071)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.082)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.094)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (3): GELU(approximate='none')\n",
              "              (4): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (4): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.106)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.118)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.129)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.141)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.153)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.165)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.176)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.188)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.200)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNLdesKoWN6C",
        "outputId": "61acc36b-a723-466d-d6f9-8b28fdea9da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 196, 384])\n"
          ]
        }
      ],
      "source": [
        "bottleneck = Bottleneck(dim=384)\n",
        "dummy_input = torch.randn(1, 32, 196, 384)  # Match your error shape\n",
        "output = bottleneck(dummy_input)\n",
        "print(output.shape)  # Should be [1, 32, 196, 384]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JQdG7pag82hn"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/MINI_PRO/MINI_PRO/training_set', transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/MINI_PRO/MINI_PRO/test_set', transform=test_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wVftc2th9QHg"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "device ='cuda'\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "model = model.to(device)\n",
        "import torch.nn as nn\n",
        "\n",
        "# Assuming your model is instantiated as 'model'\n",
        "num_features = model.model.head.in_features  # Get the input features of the current head\n",
        "model.model.head = nn.Linear(num_features, 1)  # Replace with binary classification head\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KbNBjIwpZz1",
        "outputId": "5f74fba8-7be1-4a82-839e-41c9c1e08fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 0.0050 | Test Accuracy: 0.9842 | Test AUROC: 0.9815\n",
            "\n",
            "Epoch 2/20\n",
            "Train Loss: 0.0049 | Test Accuracy: 0.9842 | Test AUROC: 0.9836\n",
            "\n",
            "Epoch 3/20\n",
            "Train Loss: 0.0038 | Test Accuracy: 0.9810 | Test AUROC: 0.9770\n",
            "\n",
            "Epoch 4/20\n",
            "Train Loss: 0.0249 | Test Accuracy: 0.9810 | Test AUROC: 0.9791\n",
            "\n",
            "Epoch 5/20\n",
            "Train Loss: 0.0063 | Test Accuracy: 0.9842 | Test AUROC: 0.9815\n",
            "\n",
            "Epoch 6/20\n",
            "Train Loss: 0.0039 | Test Accuracy: 0.9842 | Test AUROC: 0.9836\n",
            "\n",
            "Epoch 7/20\n",
            "Train Loss: 0.0047 | Test Accuracy: 0.9842 | Test AUROC: 0.9794\n",
            "\n",
            "Epoch 8/20\n",
            "Train Loss: 0.0080 | Test Accuracy: 0.9842 | Test AUROC: 0.9857\n",
            "\n",
            "Epoch 9/20\n",
            "Train Loss: 0.0221 | Test Accuracy: 0.9810 | Test AUROC: 0.9770\n",
            "\n",
            "Epoch 10/20\n",
            "Train Loss: 0.0186 | Test Accuracy: 0.9873 | Test AUROC: 0.9882\n",
            "\n",
            "Epoch 11/20\n",
            "Train Loss: 0.0132 | Test Accuracy: 0.9778 | Test AUROC: 0.9745\n",
            "\n",
            "Epoch 12/20\n",
            "Train Loss: 0.0207 | Test Accuracy: 0.9747 | Test AUROC: 0.9700\n",
            "\n",
            "Epoch 13/20\n",
            "Train Loss: 0.0120 | Test Accuracy: 0.9810 | Test AUROC: 0.9833\n",
            "\n",
            "Epoch 14/20\n",
            "Train Loss: 0.0045 | Test Accuracy: 0.9873 | Test AUROC: 0.9861\n",
            "\n",
            "Epoch 15/20\n",
            "Train Loss: 0.0081 | Test Accuracy: 0.9842 | Test AUROC: 0.9836\n",
            "\n",
            "Epoch 16/20\n",
            "Train Loss: 0.0209 | Test Accuracy: 0.9810 | Test AUROC: 0.9812\n",
            "\n",
            "Epoch 17/20\n",
            "Train Loss: 0.0112 | Test Accuracy: 0.9810 | Test AUROC: 0.9812\n",
            "\n",
            "Epoch 18/20\n",
            "Train Loss: 0.0067 | Test Accuracy: 0.9747 | Test AUROC: 0.9785\n",
            "\n",
            "Epoch 19/20\n",
            "Train Loss: 0.0053 | Test Accuracy: 0.9873 | Test AUROC: 0.9882\n",
            "\n",
            "Epoch 20/20\n",
            "Train Loss: 0.0104 | Test Accuracy: 0.9842 | Test AUROC: 0.9857\n",
            "Test Accuracy: 0.9842\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Tracking misclassified images (store filename, predicted class, true class)\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import torch\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    misclassified_info = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)[\"logits\"].squeeze()\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Get filenames for current batch\n",
        "            batch_filenames = [loader.dataset.samples[i][0] for i in\n",
        "                               range(batch_idx * loader.batch_size,\n",
        "                                     batch_idx * loader.batch_size + len(labels))]\n",
        "\n",
        "            for i in range(len(labels)):\n",
        "                pred_label = int(preds[i])\n",
        "                true_label = int(labels[i].item())\n",
        "                if pred_label != true_label:\n",
        "                    filename_short = batch_filenames[i].split(\"/\")[-1]\n",
        "                    misclassified_info.append((filename_short, pred_label, true_label))\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    auroc = roc_auc_score(all_labels, all_preds)\n",
        "\n",
        "    return accuracy, auroc, misclassified_info\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Training Loop\n",
        "# -----------------------------\n",
        "\n",
        "best_test_accuracy = 0\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)[\"logits\"].squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # Evaluate\n",
        "    test_accuracy, test_auroc, misclassified_info = evaluate(model, test_loader, device)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Test Accuracy: {test_accuracy:.4f} | Test AUROC: {test_auroc:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWfPQ23T9UAy",
        "outputId": "f1dab862-e16b-4d94-8d6d-e834751e406a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MambaVisionModelForImageClassification(\n",
              "  (model): MambaVision(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Identity()\n",
              "      (conv_down): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (levels): ModuleList(\n",
              "      (0): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.012)\n",
              "          )\n",
              "          (2): ConvBlock(\n",
              "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.024)\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.035)\n",
              "          )\n",
              "          (1): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.047)\n",
              "          )\n",
              "          (2): ConvBlock(\n",
              "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): GELU(approximate='tanh')\n",
              "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_path): DropPath(drop_prob=0.059)\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.071)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.082)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.094)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (3): GELU(approximate='none')\n",
              "              (4): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (4): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (x_proj): Linear(in_features=192, out_features=40, bias=False)\n",
              "              (dt_proj): Linear(in_features=24, out_features=192, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (conv1d_x): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "              (conv1d_z): Conv1d(192, 192, kernel_size=(3,), stride=(1,), groups=192, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.106)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.118)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.129)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): Block(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.141)\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): Downsample(\n",
              "          (reduction): Sequential(\n",
              "            (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): MambaVisionLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.153)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.165)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): MambaVisionMixer(\n",
              "              (in_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (x_proj): Linear(in_features=384, out_features=64, bias=False)\n",
              "              (dt_proj): Linear(in_features=48, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (conv1d_x): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "              (conv1d_z): Conv1d(384, 384, kernel_size=(3,), stride=(1,), groups=384, bias=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.176)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.188)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): Block(\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mixer): Attention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (q_norm): Identity()\n",
              "              (k_norm): Identity()\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.200)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (head): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48K99s_UART_",
        "outputId": "5d3362a6-baaa-4bf2-8f2c-a01dfdc71495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Test Accuracy: 66.05%\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6Bi5SWqTPAJM",
        "outputId": "a9fed40c-caed-4658-d5ff-b8994c5e4362"
      },
      "outputs": [
        {
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 241\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9de1fadd5b5d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 )\n\u001b[1;32m   1493\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         return _legacy_load(\n\u001b[1;32m   1496\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 241\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg9tdEz_PJa5",
        "outputId": "ff657b85-01c8-4e35-bf39-8c024d295ee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_model.pth: data\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "5yKF3rO2Quwp",
        "outputId": "0854e13e-7292-4f97-f8ef-79e21bbf322a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-385c5f96-bef9-4687-a4e6-103959df915a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-385c5f96-bef9-4687-a4e6-103959df915a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best_model.pth to best_model.pth\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFLzB-HKHzzE",
        "outputId": "97dd6a27-a3d4-4a57-aa8e-844306fd64c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_model.pth: Zip archive data, at least v0.0 to extract, compression method=store\n",
            "-rw-r--r-- 1 root root 221M Apr 16 16:33 best_model.pth\n"
          ]
        }
      ],
      "source": [
        "!file best_model.pth\n",
        "!ls -lh best_model.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KKxp83NY0SH",
        "outputId": "714c6c70-841c-418e-afdc-50dda739d2ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  best_model.pth\n",
            " extracting: model_zip_contents/best_model/data.pkl  \n",
            " extracting: model_zip_contents/best_model/byteorder  \n",
            " extracting: model_zip_contents/best_model/data/0  \n",
            " extracting: model_zip_contents/best_model/data/1  \n",
            " extracting: model_zip_contents/best_model/data/10  \n",
            " extracting: model_zip_contents/best_model/data/100  \n",
            " extracting: model_zip_contents/best_model/data/101  \n",
            " extracting: model_zip_contents/best_model/data/102  \n",
            " extracting: model_zip_contents/best_model/data/103  \n",
            " extracting: model_zip_contents/best_model/data/104  \n",
            " extracting: model_zip_contents/best_model/data/105  \n",
            " extracting: model_zip_contents/best_model/data/106  \n",
            " extracting: model_zip_contents/best_model/data/107  \n",
            " extracting: model_zip_contents/best_model/data/108  \n",
            " extracting: model_zip_contents/best_model/data/109  \n",
            " extracting: model_zip_contents/best_model/data/11  \n",
            " extracting: model_zip_contents/best_model/data/110  \n",
            " extracting: model_zip_contents/best_model/data/111  \n",
            " extracting: model_zip_contents/best_model/data/112  \n",
            " extracting: model_zip_contents/best_model/data/113  \n",
            " extracting: model_zip_contents/best_model/data/114  \n",
            " extracting: model_zip_contents/best_model/data/115  \n",
            " extracting: model_zip_contents/best_model/data/116  \n",
            " extracting: model_zip_contents/best_model/data/117  \n",
            " extracting: model_zip_contents/best_model/data/118  \n",
            " extracting: model_zip_contents/best_model/data/119  \n",
            " extracting: model_zip_contents/best_model/data/12  \n",
            " extracting: model_zip_contents/best_model/data/120  \n",
            " extracting: model_zip_contents/best_model/data/121  \n",
            " extracting: model_zip_contents/best_model/data/122  \n",
            " extracting: model_zip_contents/best_model/data/123  \n",
            " extracting: model_zip_contents/best_model/data/124  \n",
            " extracting: model_zip_contents/best_model/data/125  \n",
            " extracting: model_zip_contents/best_model/data/126  \n",
            " extracting: model_zip_contents/best_model/data/127  \n",
            " extracting: model_zip_contents/best_model/data/128  \n",
            " extracting: model_zip_contents/best_model/data/129  \n",
            " extracting: model_zip_contents/best_model/data/13  \n",
            " extracting: model_zip_contents/best_model/data/130  \n",
            " extracting: model_zip_contents/best_model/data/131  \n",
            " extracting: model_zip_contents/best_model/data/132  \n",
            " extracting: model_zip_contents/best_model/data/133  \n",
            " extracting: model_zip_contents/best_model/data/134  \n",
            " extracting: model_zip_contents/best_model/data/135  \n",
            " extracting: model_zip_contents/best_model/data/136  \n",
            " extracting: model_zip_contents/best_model/data/137  \n",
            " extracting: model_zip_contents/best_model/data/138  \n",
            " extracting: model_zip_contents/best_model/data/139  \n",
            " extracting: model_zip_contents/best_model/data/14  \n",
            " extracting: model_zip_contents/best_model/data/140  \n",
            " extracting: model_zip_contents/best_model/data/141  \n",
            " extracting: model_zip_contents/best_model/data/142  \n",
            " extracting: model_zip_contents/best_model/data/143  \n",
            " extracting: model_zip_contents/best_model/data/144  \n",
            " extracting: model_zip_contents/best_model/data/145  \n",
            " extracting: model_zip_contents/best_model/data/146  \n",
            " extracting: model_zip_contents/best_model/data/147  \n",
            " extracting: model_zip_contents/best_model/data/148  \n",
            " extracting: model_zip_contents/best_model/data/149  \n",
            " extracting: model_zip_contents/best_model/data/15  \n",
            " extracting: model_zip_contents/best_model/data/150  \n",
            " extracting: model_zip_contents/best_model/data/151  \n",
            " extracting: model_zip_contents/best_model/data/152  \n",
            " extracting: model_zip_contents/best_model/data/153  \n",
            " extracting: model_zip_contents/best_model/data/154  \n",
            " extracting: model_zip_contents/best_model/data/155  \n",
            " extracting: model_zip_contents/best_model/data/156  \n",
            " extracting: model_zip_contents/best_model/data/157  \n",
            " extracting: model_zip_contents/best_model/data/158  \n",
            " extracting: model_zip_contents/best_model/data/159  \n",
            " extracting: model_zip_contents/best_model/data/16  \n",
            " extracting: model_zip_contents/best_model/data/160  \n",
            " extracting: model_zip_contents/best_model/data/161  \n",
            " extracting: model_zip_contents/best_model/data/162  \n",
            " extracting: model_zip_contents/best_model/data/163  \n",
            " extracting: model_zip_contents/best_model/data/164  \n",
            " extracting: model_zip_contents/best_model/data/165  \n",
            " extracting: model_zip_contents/best_model/data/166  \n",
            " extracting: model_zip_contents/best_model/data/167  \n",
            " extracting: model_zip_contents/best_model/data/168  \n",
            " extracting: model_zip_contents/best_model/data/169  \n",
            " extracting: model_zip_contents/best_model/data/17  \n",
            " extracting: model_zip_contents/best_model/data/170  \n",
            " extracting: model_zip_contents/best_model/data/171  \n",
            " extracting: model_zip_contents/best_model/data/172  \n",
            " extracting: model_zip_contents/best_model/data/173  \n",
            " extracting: model_zip_contents/best_model/data/174  \n",
            " extracting: model_zip_contents/best_model/data/175  \n",
            " extracting: model_zip_contents/best_model/data/176  \n",
            " extracting: model_zip_contents/best_model/data/177  \n",
            " extracting: model_zip_contents/best_model/data/178  \n",
            " extracting: model_zip_contents/best_model/data/179  \n",
            " extracting: model_zip_contents/best_model/data/18  \n",
            " extracting: model_zip_contents/best_model/data/180  \n",
            " extracting: model_zip_contents/best_model/data/181  \n",
            " extracting: model_zip_contents/best_model/data/182  \n",
            " extracting: model_zip_contents/best_model/data/183  \n",
            " extracting: model_zip_contents/best_model/data/184  \n",
            " extracting: model_zip_contents/best_model/data/185  \n",
            " extracting: model_zip_contents/best_model/data/186  \n",
            " extracting: model_zip_contents/best_model/data/187  \n",
            " extracting: model_zip_contents/best_model/data/188  \n",
            " extracting: model_zip_contents/best_model/data/189  \n",
            " extracting: model_zip_contents/best_model/data/19  \n",
            " extracting: model_zip_contents/best_model/data/190  \n",
            " extracting: model_zip_contents/best_model/data/191  \n",
            " extracting: model_zip_contents/best_model/data/192  \n",
            " extracting: model_zip_contents/best_model/data/193  \n",
            " extracting: model_zip_contents/best_model/data/194  \n",
            " extracting: model_zip_contents/best_model/data/195  \n",
            " extracting: model_zip_contents/best_model/data/196  \n",
            " extracting: model_zip_contents/best_model/data/197  \n",
            " extracting: model_zip_contents/best_model/data/198  \n",
            " extracting: model_zip_contents/best_model/data/199  \n",
            " extracting: model_zip_contents/best_model/data/2  \n",
            " extracting: model_zip_contents/best_model/data/20  \n",
            " extracting: model_zip_contents/best_model/data/200  \n",
            " extracting: model_zip_contents/best_model/data/201  \n",
            " extracting: model_zip_contents/best_model/data/202  \n",
            " extracting: model_zip_contents/best_model/data/203  \n",
            " extracting: model_zip_contents/best_model/data/204  \n",
            " extracting: model_zip_contents/best_model/data/205  \n",
            " extracting: model_zip_contents/best_model/data/206  \n",
            " extracting: model_zip_contents/best_model/data/207  \n",
            " extracting: model_zip_contents/best_model/data/208  \n",
            " extracting: model_zip_contents/best_model/data/209  \n",
            " extracting: model_zip_contents/best_model/data/21  \n",
            " extracting: model_zip_contents/best_model/data/210  \n",
            " extracting: model_zip_contents/best_model/data/211  \n",
            " extracting: model_zip_contents/best_model/data/212  \n",
            " extracting: model_zip_contents/best_model/data/213  \n",
            " extracting: model_zip_contents/best_model/data/214  \n",
            " extracting: model_zip_contents/best_model/data/215  \n",
            " extracting: model_zip_contents/best_model/data/216  \n",
            " extracting: model_zip_contents/best_model/data/217  \n",
            " extracting: model_zip_contents/best_model/data/218  \n",
            " extracting: model_zip_contents/best_model/data/219  \n",
            " extracting: model_zip_contents/best_model/data/22  \n",
            " extracting: model_zip_contents/best_model/data/220  \n",
            " extracting: model_zip_contents/best_model/data/221  \n",
            " extracting: model_zip_contents/best_model/data/222  \n",
            " extracting: model_zip_contents/best_model/data/223  \n",
            " extracting: model_zip_contents/best_model/data/224  \n",
            " extracting: model_zip_contents/best_model/data/225  \n",
            " extracting: model_zip_contents/best_model/data/226  \n",
            " extracting: model_zip_contents/best_model/data/227  \n",
            " extracting: model_zip_contents/best_model/data/228  \n",
            " extracting: model_zip_contents/best_model/data/229  \n",
            " extracting: model_zip_contents/best_model/data/23  \n",
            " extracting: model_zip_contents/best_model/data/230  \n",
            " extracting: model_zip_contents/best_model/data/231  \n",
            " extracting: model_zip_contents/best_model/data/232  \n",
            " extracting: model_zip_contents/best_model/data/233  \n",
            " extracting: model_zip_contents/best_model/data/234  \n",
            " extracting: model_zip_contents/best_model/data/235  \n",
            " extracting: model_zip_contents/best_model/data/236  \n",
            " extracting: model_zip_contents/best_model/data/237  \n",
            " extracting: model_zip_contents/best_model/data/238  \n",
            " extracting: model_zip_contents/best_model/data/239  \n",
            " extracting: model_zip_contents/best_model/data/24  \n",
            " extracting: model_zip_contents/best_model/data/240  \n",
            " extracting: model_zip_contents/best_model/data/241  \n",
            " extracting: model_zip_contents/best_model/data/242  \n",
            " extracting: model_zip_contents/best_model/data/243  \n",
            " extracting: model_zip_contents/best_model/data/244  \n",
            " extracting: model_zip_contents/best_model/data/245  \n",
            " extracting: model_zip_contents/best_model/data/246  \n",
            " extracting: model_zip_contents/best_model/data/247  \n",
            " extracting: model_zip_contents/best_model/data/248  \n",
            " extracting: model_zip_contents/best_model/data/249  \n",
            " extracting: model_zip_contents/best_model/data/25  \n",
            " extracting: model_zip_contents/best_model/data/250  \n",
            " extracting: model_zip_contents/best_model/data/251  \n",
            " extracting: model_zip_contents/best_model/data/252  \n",
            " extracting: model_zip_contents/best_model/data/253  \n",
            " extracting: model_zip_contents/best_model/data/254  \n",
            " extracting: model_zip_contents/best_model/data/255  \n",
            " extracting: model_zip_contents/best_model/data/256  \n",
            " extracting: model_zip_contents/best_model/data/257  \n",
            " extracting: model_zip_contents/best_model/data/258  \n",
            " extracting: model_zip_contents/best_model/data/259  \n",
            " extracting: model_zip_contents/best_model/data/26  \n",
            " extracting: model_zip_contents/best_model/data/260  \n",
            " extracting: model_zip_contents/best_model/data/261  \n",
            " extracting: model_zip_contents/best_model/data/262  \n",
            " extracting: model_zip_contents/best_model/data/263  \n",
            " extracting: model_zip_contents/best_model/data/264  \n",
            " extracting: model_zip_contents/best_model/data/265  \n",
            " extracting: model_zip_contents/best_model/data/266  \n",
            " extracting: model_zip_contents/best_model/data/267  \n",
            " extracting: model_zip_contents/best_model/data/268  \n",
            " extracting: model_zip_contents/best_model/data/269  \n",
            " extracting: model_zip_contents/best_model/data/27  \n",
            " extracting: model_zip_contents/best_model/data/270  \n",
            " extracting: model_zip_contents/best_model/data/271  \n",
            " extracting: model_zip_contents/best_model/data/272  \n",
            " extracting: model_zip_contents/best_model/data/273  \n",
            " extracting: model_zip_contents/best_model/data/274  \n",
            " extracting: model_zip_contents/best_model/data/275  \n",
            " extracting: model_zip_contents/best_model/data/276  \n",
            " extracting: model_zip_contents/best_model/data/277  \n",
            " extracting: model_zip_contents/best_model/data/278  \n",
            " extracting: model_zip_contents/best_model/data/279  \n",
            " extracting: model_zip_contents/best_model/data/28  \n",
            " extracting: model_zip_contents/best_model/data/280  \n",
            " extracting: model_zip_contents/best_model/data/281  \n",
            " extracting: model_zip_contents/best_model/data/282  \n",
            " extracting: model_zip_contents/best_model/data/283  \n",
            " extracting: model_zip_contents/best_model/data/284  \n",
            " extracting: model_zip_contents/best_model/data/285  \n",
            " extracting: model_zip_contents/best_model/data/286  \n",
            " extracting: model_zip_contents/best_model/data/287  \n",
            " extracting: model_zip_contents/best_model/data/288  \n",
            " extracting: model_zip_contents/best_model/data/289  \n",
            " extracting: model_zip_contents/best_model/data/29  \n",
            " extracting: model_zip_contents/best_model/data/290  \n",
            " extracting: model_zip_contents/best_model/data/291  \n",
            " extracting: model_zip_contents/best_model/data/292  \n",
            " extracting: model_zip_contents/best_model/data/293  \n",
            " extracting: model_zip_contents/best_model/data/294  \n",
            " extracting: model_zip_contents/best_model/data/295  \n",
            " extracting: model_zip_contents/best_model/data/3  \n",
            " extracting: model_zip_contents/best_model/data/30  \n",
            " extracting: model_zip_contents/best_model/data/31  \n",
            " extracting: model_zip_contents/best_model/data/32  \n",
            " extracting: model_zip_contents/best_model/data/33  \n",
            " extracting: model_zip_contents/best_model/data/34  \n",
            " extracting: model_zip_contents/best_model/data/35  \n",
            " extracting: model_zip_contents/best_model/data/36  \n",
            " extracting: model_zip_contents/best_model/data/37  \n",
            " extracting: model_zip_contents/best_model/data/38  \n",
            " extracting: model_zip_contents/best_model/data/39  \n",
            " extracting: model_zip_contents/best_model/data/4  \n",
            " extracting: model_zip_contents/best_model/data/40  \n",
            " extracting: model_zip_contents/best_model/data/41  \n",
            " extracting: model_zip_contents/best_model/data/42  \n",
            " extracting: model_zip_contents/best_model/data/43  \n",
            " extracting: model_zip_contents/best_model/data/44  \n",
            " extracting: model_zip_contents/best_model/data/45  \n",
            " extracting: model_zip_contents/best_model/data/46  \n",
            " extracting: model_zip_contents/best_model/data/47  \n",
            " extracting: model_zip_contents/best_model/data/48  \n",
            " extracting: model_zip_contents/best_model/data/49  \n",
            " extracting: model_zip_contents/best_model/data/5  \n",
            " extracting: model_zip_contents/best_model/data/50  \n",
            " extracting: model_zip_contents/best_model/data/51  \n",
            " extracting: model_zip_contents/best_model/data/52  \n",
            " extracting: model_zip_contents/best_model/data/53  \n",
            " extracting: model_zip_contents/best_model/data/54  \n",
            " extracting: model_zip_contents/best_model/data/55  \n",
            " extracting: model_zip_contents/best_model/data/56  \n",
            " extracting: model_zip_contents/best_model/data/57  \n",
            " extracting: model_zip_contents/best_model/data/58  \n",
            " extracting: model_zip_contents/best_model/data/59  \n",
            " extracting: model_zip_contents/best_model/data/6  \n",
            " extracting: model_zip_contents/best_model/data/60  \n",
            " extracting: model_zip_contents/best_model/data/61  \n",
            " extracting: model_zip_contents/best_model/data/62  \n",
            " extracting: model_zip_contents/best_model/data/63  \n",
            " extracting: model_zip_contents/best_model/data/64  \n",
            " extracting: model_zip_contents/best_model/data/65  \n",
            " extracting: model_zip_contents/best_model/data/66  \n",
            " extracting: model_zip_contents/best_model/data/67  \n",
            " extracting: model_zip_contents/best_model/data/68  \n",
            " extracting: model_zip_contents/best_model/data/69  \n",
            " extracting: model_zip_contents/best_model/data/7  \n",
            " extracting: model_zip_contents/best_model/data/70  \n",
            " extracting: model_zip_contents/best_model/data/71  \n",
            " extracting: model_zip_contents/best_model/data/72  \n",
            " extracting: model_zip_contents/best_model/data/73  \n",
            " extracting: model_zip_contents/best_model/data/74  \n",
            " extracting: model_zip_contents/best_model/data/75  \n",
            " extracting: model_zip_contents/best_model/data/76  \n",
            " extracting: model_zip_contents/best_model/data/77  \n",
            " extracting: model_zip_contents/best_model/data/78  \n",
            " extracting: model_zip_contents/best_model/data/79  \n",
            " extracting: model_zip_contents/best_model/data/8  \n",
            " extracting: model_zip_contents/best_model/data/80  \n",
            " extracting: model_zip_contents/best_model/data/81  \n",
            " extracting: model_zip_contents/best_model/data/82  \n",
            " extracting: model_zip_contents/best_model/data/83  \n",
            " extracting: model_zip_contents/best_model/data/84  \n",
            " extracting: model_zip_contents/best_model/data/85  \n",
            " extracting: model_zip_contents/best_model/data/86  \n",
            " extracting: model_zip_contents/best_model/data/87  \n",
            " extracting: model_zip_contents/best_model/data/88  \n",
            " extracting: model_zip_contents/best_model/data/89  \n",
            " extracting: model_zip_contents/best_model/data/9  \n",
            " extracting: model_zip_contents/best_model/data/90  \n",
            " extracting: model_zip_contents/best_model/data/91  \n",
            " extracting: model_zip_contents/best_model/data/92  \n",
            " extracting: model_zip_contents/best_model/data/93  \n",
            " extracting: model_zip_contents/best_model/data/94  \n",
            " extracting: model_zip_contents/best_model/data/95  \n",
            " extracting: model_zip_contents/best_model/data/96  \n",
            " extracting: model_zip_contents/best_model/data/97  \n",
            " extracting: model_zip_contents/best_model/data/98  \n",
            " extracting: model_zip_contents/best_model/data/99  \n",
            " extracting: model_zip_contents/best_model/version  \n",
            " extracting: model_zip_contents/best_model/.data/serialization_id  \n"
          ]
        }
      ],
      "source": [
        "!unzip best_model.pth -d model_zip_contents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc62rlLreoV5",
        "outputId": "ccba7768-13ae-487e-f973-4c5fde6d1735"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['best_model']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!!ls model_zip_contents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ5KLIjrerJo",
        "outputId": "d5f569bb-3300-4172-8b23-5d5005f3dd57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_zip_contents/best_model: cannot open `model_zip_contents/best_model' (No such file or directory)\n"
          ]
        }
      ],
      "source": [
        "!file model_zip_contents/best_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVhL3gyleyNW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "99bce7417e3e409c9352dc0efab86e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1e454d20d94cc38ed099398315e7f3",
              "IPY_MODEL_f675afd08b7645e5a9156c39c7acce2d",
              "IPY_MODEL_12e1e806f2fb47dd8de55616ac0fcdad"
            ],
            "layout": "IPY_MODEL_6f8275931dc9491b9ffd79894d8b54db"
          }
        },
        "ee1e454d20d94cc38ed099398315e7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a497dacf53487bba75f59b7f8aeb5b",
            "placeholder": "​",
            "style": "IPY_MODEL_749ab214d5ff486a927cedda31a39846",
            "value": "config.json: 100%"
          }
        },
        "f675afd08b7645e5a9156c39c7acce2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f0553c5f8594bb6be48e5471adf3d31",
            "max": 36361,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6612fae12b0e4591b2d67ed9bac634db",
            "value": 36361
          }
        },
        "12e1e806f2fb47dd8de55616ac0fcdad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90317f08b5c94bda9423adea0db29fa7",
            "placeholder": "​",
            "style": "IPY_MODEL_624a4787857c405eb34490a614873963",
            "value": " 36.4k/36.4k [00:00&lt;00:00, 3.08MB/s]"
          }
        },
        "6f8275931dc9491b9ffd79894d8b54db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a497dacf53487bba75f59b7f8aeb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749ab214d5ff486a927cedda31a39846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f0553c5f8594bb6be48e5471adf3d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6612fae12b0e4591b2d67ed9bac634db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90317f08b5c94bda9423adea0db29fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624a4787857c405eb34490a614873963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfe6973bd09947adb3fd66fe731cc1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0b62aa585d2446cbafd7b9a1146eb05",
              "IPY_MODEL_33317b06342d48bf970e7c1e198933a8",
              "IPY_MODEL_5b918885e96d42abae50853ebee19fd7"
            ],
            "layout": "IPY_MODEL_61798c596d8d4ab9ad967eaa557b3dc7"
          }
        },
        "f0b62aa585d2446cbafd7b9a1146eb05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26f95247cb9c4a63b5aeae9c0ff4e0ad",
            "placeholder": "​",
            "style": "IPY_MODEL_156701ddeff3424aa4e7bc0c76201bc8",
            "value": "configuration_mambavision.py: 100%"
          }
        },
        "33317b06342d48bf970e7c1e198933a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810432b8707947f09b505f25cffffdda",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be1c94bed8cb425d9124b92e19eaddbf",
            "value": 625
          }
        },
        "5b918885e96d42abae50853ebee19fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35dfce8ee4b442c2804575046575732f",
            "placeholder": "​",
            "style": "IPY_MODEL_2b5e9eead7a742088d4180875208585c",
            "value": " 625/625 [00:00&lt;00:00, 66.7kB/s]"
          }
        },
        "61798c596d8d4ab9ad967eaa557b3dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f95247cb9c4a63b5aeae9c0ff4e0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "156701ddeff3424aa4e7bc0c76201bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "810432b8707947f09b505f25cffffdda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be1c94bed8cb425d9124b92e19eaddbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35dfce8ee4b442c2804575046575732f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5e9eead7a742088d4180875208585c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fba137eba28b439e805b4969b560d0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c875a0ec13d4442ca3231c612d99694f",
              "IPY_MODEL_b25440fd3f4e4a81af2e1e64992b0478",
              "IPY_MODEL_3440f6a96b494219b3168b1aa8c6568b"
            ],
            "layout": "IPY_MODEL_10f63769b1324b809b5b8386998b35f3"
          }
        },
        "c875a0ec13d4442ca3231c612d99694f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6040c6a40ae04c6893fc70f50a23a7fb",
            "placeholder": "​",
            "style": "IPY_MODEL_cfdb94c1ba1b4e6fa8108355c3b936cf",
            "value": "modeling_mambavision.py: 100%"
          }
        },
        "b25440fd3f4e4a81af2e1e64992b0478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d23f65cb3b4b4a6c954cb58bbff46597",
            "max": 27908,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50c8c4aa4288459eb9e7934c13244e65",
            "value": 27908
          }
        },
        "3440f6a96b494219b3168b1aa8c6568b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85d0b93f3fb042f68c34a5d32f7bd864",
            "placeholder": "​",
            "style": "IPY_MODEL_75d314ded7a94790a9a8ce32b746a3dd",
            "value": " 27.9k/27.9k [00:00&lt;00:00, 2.81MB/s]"
          }
        },
        "10f63769b1324b809b5b8386998b35f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6040c6a40ae04c6893fc70f50a23a7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfdb94c1ba1b4e6fa8108355c3b936cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d23f65cb3b4b4a6c954cb58bbff46597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c8c4aa4288459eb9e7934c13244e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85d0b93f3fb042f68c34a5d32f7bd864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d314ded7a94790a9a8ce32b746a3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37344e75c2254792baf3bd93df24057f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebe82190935944bfa8e91176f2a9dc3a",
              "IPY_MODEL_50c1a5e0a3b84c7cb920c67600ebb67f",
              "IPY_MODEL_b9d79fa7ebe44c99b687194e7139146b"
            ],
            "layout": "IPY_MODEL_0974808b8f5644e2a97e87029168bea3"
          }
        },
        "ebe82190935944bfa8e91176f2a9dc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7fe137f1abb4f00a97c637b9469227e",
            "placeholder": "​",
            "style": "IPY_MODEL_53078cb4c3db411a8c76d351d550b44b",
            "value": "model.safetensors: 100%"
          }
        },
        "50c1a5e0a3b84c7cb920c67600ebb67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef8ebbb92f6483b8fa8f070ba3fc44c",
            "max": 200614224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a486c47a098445a95e4b840f3a292ea",
            "value": 200614224
          }
        },
        "b9d79fa7ebe44c99b687194e7139146b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_868c8fdb7d874b699c892fe317460958",
            "placeholder": "​",
            "style": "IPY_MODEL_1111fa5d733a4138baa23a6df22c55c2",
            "value": " 201M/201M [00:01&lt;00:00, 196MB/s]"
          }
        },
        "0974808b8f5644e2a97e87029168bea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7fe137f1abb4f00a97c637b9469227e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53078cb4c3db411a8c76d351d550b44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef8ebbb92f6483b8fa8f070ba3fc44c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a486c47a098445a95e4b840f3a292ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "868c8fdb7d874b699c892fe317460958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1111fa5d733a4138baa23a6df22c55c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}